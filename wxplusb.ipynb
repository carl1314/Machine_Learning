{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wxplusb.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/LjBLincoln/Machine_Learning/blob/master/wxplusb.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "FIUgh1RYv7-k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Create Train Data and Test Data**"
      ]
    },
    {
      "metadata": {
        "id": "4bzN1lo4SpDa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np \n",
        "\n",
        "TRAIN_DATA = 8000\n",
        "TEST_DATA = 20000\n",
        "\n",
        "TRAIN_DATA_FILE = 'train'\n",
        "TEST_DATA_FILE = 'test'\n",
        "\n",
        "def create_DATA(file):\n",
        "    if (os.path.isfile(file)):\n",
        "        x_data = np.loadtxt(file)\n",
        "    else:\n",
        "        X = np.random.rand(TRAIN_DATA).astype(np.float32)\n",
        "        x_data = np.array([X,np.random.uniform(0,3, TRAIN_DATA) + X]).reshape(TRAIN_DATA,2)\n",
        "        np.savetxt(file,x_data)\n",
        "    \n",
        "    #print(x_data)\n",
        "\n",
        "create_DATA(TRAIN_DATA_FILE)\n",
        "create_DATA(TEST_DATA_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "id4g8pC0xg3G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Create TFRecord **"
      ]
    },
    {
      "metadata": {
        "id": "IODU2CDUxtDb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import os \n",
        "import tensorflow as tf\n",
        "\n",
        "TRAIN_DATA_FILE = 'train'\n",
        "TEST_DATA_FILE = 'test'\n",
        "\n",
        "def _float_feature(value):\n",
        "    return tf.train.Feature(float_list = tf.train.FloatList(value = [value]))\n",
        "  \n",
        "def create_TFRecord(file):\n",
        "    classes = np.loadtxt(file)\n",
        "\n",
        "    writer = tf.python_io.TFRecordWriter(file +'.tfrecords')\n",
        "\n",
        "    for index, data in enumerate(classes):\n",
        "        print(index,data[0],data[1]) \n",
        "        example = tf.train.Example(features = tf.train.Features(feature = {\"y_data\": _float_feature(data[1]),\n",
        "                                                                           \"x_data\": _float_feature(data[0]),                                                                          \n",
        "                                                                            }))\n",
        "        writer.write(example.SerializeToString()) \n",
        "    writer.close()\n",
        "  \n",
        "create_TFRecord(TRAIN_DATA_FILE)\n",
        "create_TFRecord(TEST_DATA_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g0uhrL_wB853",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Read TFRecord **"
      ]
    },
    {
      "metadata": {
        "id": "JnQNHIFEYqNs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def read_and_decode(filename, batch_size): # read train.tfrecords\n",
        "    filename_queue = tf.train.string_input_producer([filename])# create a queue\n",
        "\n",
        "    reader = tf.TFRecordReader()\n",
        "    _, serialized_example = reader.read(filename_queue)#return file_name and file\n",
        "    features = tf.parse_single_example(serialized_example,\n",
        "                                       features={\n",
        "                                           'x_data': tf.FixedLenFeature([], tf.float32),\n",
        "                                           'y_data' : tf.FixedLenFeature([], tf.float32),\n",
        "                                       })#return image and label\n",
        "\n",
        "    X_ = tf.cast(features['x_data'], tf.float32)\n",
        "    Y_ = tf.cast(features['y_data'], tf.float32) \n",
        "\n",
        "    x_batch, y_batch = tf.train.shuffle_batch([X_, Y_],\n",
        "                                                    batch_size= batch_size,\n",
        "                                                    num_threads=64,\n",
        "                                                    capacity=2000,\n",
        "                                                    min_after_dequeue=1500,\n",
        "                                                    )\n",
        "    return x_batch, tf.reshape(y_batch,[batch_size])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gqOznSE1o3cZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Show TFRecords**"
      ]
    },
    {
      "metadata": {
        "id": "D1SmdM2po7VS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "tfrecords_file = 'train.tfrecords'\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "x_batch, y_batch = read_and_decode(tfrecords_file, BATCH_SIZE)\n",
        "\n",
        "with tf.Session()  as sess:\n",
        "\n",
        "    i = 0\n",
        "    coord = tf.train.Coordinator()\n",
        "    threads = tf.train.start_queue_runners(coord=coord)\n",
        "\n",
        "    try:\n",
        "        while not coord.should_stop() and i<8000:\n",
        "            # just plot one batch size\n",
        "            x, y = sess.run([x_batch, y_batch])\n",
        "            for j in np.arange(BATCH_SIZE):\n",
        "                print(x)\n",
        "                print(y)\n",
        "            i+=1\n",
        "    except tf.errors.OutOfRangeError:\n",
        "        print('done!')\n",
        "    finally:\n",
        "        coord.request_stop()\n",
        "    coord.join(threads)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_UWSzmb_3sIM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classes = np.loadtxt('train.txt')\n",
        "\n",
        "for index, x_data in enumerate(classes):\n",
        "    print(index,x_data[0],x_data[1])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "toYgfmOAjL-F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Demo (y = wx+b)"
      ]
    },
    {
      "metadata": {
        "id": "ZqOUVlNwjEin",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# _*_ coding: utf-8 _*_\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "\n",
        "MAX_STEPS = 1000\n",
        "\n",
        "NUM_EXAMPLES = 10000\n",
        "\n",
        "MIN_X = 0\n",
        "MIN_Y = 0\n",
        "MAX_X = 1\n",
        "MAX_Y = 1\n",
        "\n",
        "\n",
        "if (os.path.isfile('train.txt')):\n",
        "    x_data = np.loadtxt('train.txt')\n",
        "else:\n",
        "    X = np.random.rand(NUM_EXAMPLES).astype(np.float32).reshape(1,100)\n",
        "    x_data = np.array([X,np.random.uniform(MIN_Y,MAX_Y, NUM_EXAMPLES)] + X )\n",
        "    np.savetxt('train.txt',x_data)\n",
        "    \n",
        "if (os.path.isfile('test.txt')):\n",
        "    x_data = np.loadtxt('test.txt')\n",
        "else:\n",
        "    X = np.random.rand(NUM_EXAMPLES).astype(np.float32)\n",
        "    x_data = np.array([X,np.random.uniform(MIN_Y,MAX_Y, NUM_EXAMPLES)] + X )\n",
        "    np.savetxt('test.txt',x_data)\n",
        "\n",
        "#input\n",
        "with tf.name_scope('input'):\n",
        "    with tf.name_scope('x'):\n",
        "        x = tf.placeholder(tf.float32, shape = (100,), name = \"x\")\n",
        "    with tf.name_scope('y_'):\n",
        "        y_ = tf.placeholder(tf.float32, shape = (100,), name = \"y_\")\n",
        "\n",
        "# layer\n",
        "with tf.name_scope('layer'):\n",
        "    with tf.name_scope('weights'):\n",
        "        ###对权进行赋值 在-1到1之间随机数\n",
        "        Weights = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
        "        tf.summary.histogram('Weights' ,Weights)\n",
        "    with tf.name_scope('biases'):\n",
        "        #初始偏差为零\n",
        "        biases = tf.Variable(tf.zeros([1]))\n",
        "        tf.summary.histogram('biases' ,biases)\n",
        "    with tf.name_scope('Wx_plus_b'):\n",
        "        #权值与x相乘并加偏差\n",
        "        y = Weights * x + biases \n",
        "\n",
        "#Mean Squared Error)\n",
        "with tf.name_scope('Mean_Squared_Error'):\n",
        "    #方差，(y-y_)平方，求和，取均值\n",
        "    loss = tf.reduce_mean(tf.square(y-y_))\n",
        "    tf.summary.scalar('loss', loss)\n",
        "\n",
        "#Optimizer\n",
        "with tf.name_scope('train'):\n",
        "    #定义梯度下降法优化函数优化，步长为0.5\n",
        "    optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
        "    #tf.summary.scalar('optimizer', optimizer)\n",
        "    train_step = optimizer.minimize(loss)\n",
        "\n",
        "  \n",
        "def feed_dict():\n",
        "    xs, ys =x_data[0], x_data[1]\n",
        "    return {x:xs, y_:ys}\n",
        "\n",
        "\n",
        "merged = tf.summary.merge_all()\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "#session\n",
        "sess = tf.Session()\n",
        "\n",
        "#create FileWriter and loadd graph\n",
        "train_writer = tf.summary.FileWriter('./log', sess.graph)\n",
        "\n",
        "sess.run(init)\n",
        "\n",
        "plt.figure(figsize=(10, 10), dpi=80)\n",
        "plt.ion()\n",
        "\n",
        "#Save\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "for step in range(MAX_STEPS):\n",
        "    \n",
        "    plt.title(\" Diagram.\")\n",
        "    plt.xlabel(\"x_data\")\n",
        "    plt.ylabel(\"y_\")\n",
        "    plt.xlim(xmax=MAX_X, xmin=MIN_X)\n",
        "    plt.ylim(ymax=MAX_Y,ymin=MIN_Y)\n",
        "    plt.plot(x_data[0],x_data[1],'ro',color='b',linewidth=0.5)\n",
        "\n",
        "    run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
        "    summary,y_re,loss_value, _ = sess.run([merged,y,loss,train_step],feed_dict=feed_dict(),options=run_options)\n",
        "    train_writer.add_summary(summary, step)\n",
        "    print(feed_dict())\n",
        "    if step % 50 == 0:\n",
        "      print(\"After %d training step(s), loss on training batch is %g.\" %(step, loss_value))\n",
        "      saver.save(sess,'./log/models/mnist_model.ckpt', global_step=step)\n",
        "    \n",
        "    \n",
        "    if step % 50 == 0:\n",
        "        plt.plot(x_data[0],y_re,'ro', color='g',linewidth=0.5)\n",
        "    if loss_value <= 0.0863299:\n",
        "        plt.plot(x_data[0],y_re,'ro', color='r',linewidth=0.5)\n",
        "        \n",
        "\n",
        "\n",
        "plt.ioff()\n",
        "plt.show()\n",
        "    \n",
        "#close FileWriter\n",
        "train_writer.close()\n",
        "sess.close()\n",
        "\n",
        "print(\"Done !!!\")\n",
        "\n",
        "#https://www.dlology.com/blog/quick-guide-to-run-tensorboard-in-google-colab/\n",
        "\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw('tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'.format(LOG_DIR))\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9zgjhJNWhxpT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "MAX_STEPS = 500\n",
        "\n",
        "NUM_EXAMPLES = 10000\n",
        "\n",
        "# create data 生成100个0-1之间的随机数   np.random.rand(100) 1*100的矩阵，其每个元素为0-1的随机数\n",
        "#x_data = np.random.rand(NUM_EXAMPLES).astype(np.float32)\n",
        "\n",
        "#y_data = x_data\n",
        "\n",
        "#x_data =np.array([np.random.uniform(1,1.2, NUM_EXAMPLES),np.random.uniform(1,1.2, NUM_EXAMPLES)]) #np.array([np.linspace(1, 4, NUM_EXAMPLES), np.linspace(3, 9, NUM_EXAMPLES)])\n",
        "X = np.random.rand(NUM_EXAMPLES).astype(np.float32)\n",
        "#print(X)\n",
        "x_data = np.array([X,np.random.uniform(0,1, NUM_EXAMPLES)] + X ).reshape(NUM_EXAMPLES,2)\n",
        "print(x_data)\n",
        "\n",
        "plt.figure(figsize=(10, 10), dpi=80)\n",
        "plt.ion()\n",
        "plt.title(\" Diagram.\")\n",
        "plt.xlabel(\"x_data\")\n",
        "plt.ylabel(\"y_\")\n",
        "#plt.xlim(xmax=1, xmin=0)\n",
        "#plt.ylim(ymax=1,ymin=0)\n",
        "plt.plot(x_data[0:1],x_data[0:1],'ro',color='r',linewidth=0.5)\n",
        "plt.ioff()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "48dAHxOk1Xn2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls -la"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}