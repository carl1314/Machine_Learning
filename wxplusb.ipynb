{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wxplusb.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "wmpy_s3DYNFb",
        "toTJiz6iYAuC"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/LjBLincoln/Machine_Learning/blob/master/wxplusb.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "FIUgh1RYv7-k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Create Train Data and Test Data**"
      ]
    },
    {
      "metadata": {
        "id": "4bzN1lo4SpDa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np \n",
        "\n",
        "TRAIN_DATA = 800\n",
        "TEST_DATA = 200\n",
        "\n",
        "TRAIN_DATA_FILE =  'train'\n",
        "TEST_DATA_FILE =  'test'\n",
        "\n",
        "def create_DATA(file,type):\n",
        "    if (os.path.isfile(file)):\n",
        "        x_data = np.loadtxt(file)\n",
        "    else:\n",
        "        X = np.random.rand(type).astype(np.float32)\n",
        "        x_data = np.array([X,np.random.uniform(0,3, type) + X]).reshape(type,2)\n",
        "        np.savetxt(file,x_data)\n",
        "    \n",
        "    #print(x_data)\n",
        "\n",
        "create_DATA(TRAIN_DATA_FILE,TRAIN_DATA)\n",
        "create_DATA(TEST_DATA_FILE,TEST_DATA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "id4g8pC0xg3G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Create TFRecord **"
      ]
    },
    {
      "metadata": {
        "id": "IODU2CDUxtDb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import os \n",
        "import tensorflow as tf\n",
        "\n",
        "TRAIN_DATA_FILE = 'train'\n",
        "TEST_DATA_FILE = 'test'\n",
        "\n",
        "def _float_feature(value):\n",
        "    return tf.train.Feature(float_list = tf.train.FloatList(value = [value]))\n",
        "  \n",
        "def create_TFRecord(file):\n",
        "    classes = np.loadtxt(file)\n",
        "    #print(classes) \n",
        "    writer = tf.python_io.TFRecordWriter(file +'.tfrecords')\n",
        "\n",
        "    for index, data in enumerate(classes):\n",
        "        #print(index,data[0],data[1]) \n",
        "        example = tf.train.Example(features = tf.train.Features(feature = {\"y_data\": _float_feature(data[1]),\n",
        "                                                                           \"x_data\": _float_feature(data[0]),                                                                          \n",
        "                                                                            }))\n",
        "        writer.write(example.SerializeToString()) \n",
        "    writer.close()\n",
        "  \n",
        "create_TFRecord(TRAIN_DATA_FILE)\n",
        "create_TFRecord(TEST_DATA_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g0uhrL_wB853",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Read TFRecord **"
      ]
    },
    {
      "metadata": {
        "id": "NUBwn52wwWzt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Methord-One**"
      ]
    },
    {
      "metadata": {
        "id": "JnQNHIFEYqNs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "dd4a1d33-755d-4bd5-ad79-b091d8a2abe4"
      },
      "cell_type": "code",
      "source": [
        "'''import tensorflow as tf\n",
        "\n",
        "\n",
        "def read_and_decode_one(filename, batch_size): # read train.tfrecords\n",
        "    filename_queue = tf.train.string_input_producer([filename])# create a queue\n",
        "\n",
        "    reader = tf.TFRecordReader()\n",
        "    _, serialized_example = reader.read(filename_queue)#return file_name and file\n",
        "    features = tf.parse_single_example(serialized_example,\n",
        "                                       features={\n",
        "                                           'x_data': tf.FixedLenFeature([], tf.float32),\n",
        "                                           'y_data' : tf.FixedLenFeature([], tf.float32),\n",
        "                                       })#return image and label\n",
        "\n",
        "    X_ = tf.cast(features['x_data'], tf.float32)\n",
        "    Y_ = tf.cast(features['y_data'], tf.float32) \n",
        "\n",
        "    x_batch, y_batch = tf.train.shuffle_batch([X_, Y_],\n",
        "                                                    batch_size= batch_size,\n",
        "                                                    num_threads=64,\n",
        "                                                    capacity=2000,\n",
        "                                                    min_after_dequeue=1500,\n",
        "                                                    )\n",
        "    print(x_batch)\n",
        "    print(y_batch)\n",
        "    return x_batch, tf.reshape(y_batch,[batch_size])\n",
        "'''"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"import tensorflow as tf\\n\\n\\ndef read_and_decode_one(filename, batch_size): # read train.tfrecords\\n    filename_queue = tf.train.string_input_producer([filename])# create a queue\\n\\n    reader = tf.TFRecordReader()\\n    _, serialized_example = reader.read(filename_queue)#return file_name and file\\n    features = tf.parse_single_example(serialized_example,\\n                                       features={\\n                                           'x_data': tf.FixedLenFeature([], tf.float32),\\n                                           'y_data' : tf.FixedLenFeature([], tf.float32),\\n                                       })#return image and label\\n\\n    X_ = tf.cast(features['x_data'], tf.float32)\\n    Y_ = tf.cast(features['y_data'], tf.float32) \\n\\n    x_batch, y_batch = tf.train.shuffle_batch([X_, Y_],\\n                                                    batch_size= batch_size,\\n                                                    num_threads=64,\\n                                                    capacity=2000,\\n                                                    min_after_dequeue=1500,\\n                                                    )\\n    print(x_batch)\\n    print(y_batch)\\n    return x_batch, tf.reshape(y_batch,[batch_size])\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "JJQ_PB83weF6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Methord-Two**"
      ]
    },
    {
      "metadata": {
        "id": "o7ZdSZDMfVDE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c7ae8e8e-def0-4b58-f9b6-abd97b732e29"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.contrib.learn.python.learn.datasets import base\n",
        "\n",
        "\n",
        "def pares_tfrecorder(serialized_example):\n",
        "    features = tf.parse_single_example(serialized_example,\n",
        "                                       features={\n",
        "                                           'x_data': tf.FixedLenFeature([], tf.float32),\n",
        "                                           'y_data' : tf.FixedLenFeature([], tf.float32),\n",
        "                                       })\n",
        "\n",
        "    X_ = tf.cast(features['x_data'], tf.float32)\n",
        "    Y_ = tf.cast(features['y_data'], tf.float32) \n",
        "\n",
        "    return X_,Y_\n",
        "\n",
        "def read_and_decode_two(filename,batch):\n",
        "    dataset = tf.data.TFRecordDataset(filename)\n",
        "    #print(dataset)\n",
        "    dataset = dataset.map(pares_tfrecorder)\n",
        "    dataset = dataset.batch(batch).repeat(1)\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "'''\n",
        "tfrecords_file = 'train.tfrecords'\n",
        "\n",
        "BATCH_SIZE = 20\n",
        "data = read_and_decode(tfrecords_file,BATCH_SIZE)\n",
        "\n",
        "iterator = data.make_one_shot_iterator()\n",
        "\n",
        "Xs,Ys = iterator.get_next()\n",
        "\n",
        "print(Xs,Ys)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  print(sess.run([Xs,Ys]))\n",
        "'''"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ntfrecords_file = 'train.tfrecords'\\n\\nBATCH_SIZE = 20\\ndata = read_and_decode(tfrecords_file,BATCH_SIZE)\\n\\niterator = data.make_one_shot_iterator()\\n\\nXs,Ys = iterator.get_next()\\n\\nprint(Xs,Ys)\\n\\nwith tf.Session() as sess:\\n  print(sess.run([Xs,Ys]))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "gqOznSE1o3cZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Show TFRecords**"
      ]
    },
    {
      "metadata": {
        "id": "D1SmdM2po7VS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "aa4c295c-9f3f-49d1-9e95-326e268f43c5"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "import numpy as np \n",
        "\n",
        "tfrecords_file = 'train.tfrecords'\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "x_batch, y_batch = read_and_decode_one(tfrecords_file, BATCH_SIZE)\n",
        "#print(x_batch)\n",
        "#print(y_batch)\n",
        "with tf.Session()  as sess:\n",
        "\n",
        "    i = 0\n",
        "    coord = tf.train.Coordinator()\n",
        "    threads = tf.train.start_queue_runners(coord=coord)\n",
        "\n",
        "    try:\n",
        "        while not coord.should_stop() and i<1:\n",
        "            # just plot one batch size\n",
        "            x, y = sess.run([x_batch, y_batch])\n",
        "            for j in np.arange(BATCH_SIZE):\n",
        "                print(y_batch)\n",
        "                print(y)\n",
        "            i+=1\n",
        "    except tf.errors.OutOfRangeError:\n",
        "        print('done!')\n",
        "    finally:\n",
        "        coord.request_stop()\n",
        "    coord.join(threads)\n",
        "'''"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nimport numpy as np \\n\\ntfrecords_file = 'train.tfrecords'\\n\\nBATCH_SIZE = 8\\nx_batch, y_batch = read_and_decode_one(tfrecords_file, BATCH_SIZE)\\n#print(x_batch)\\n#print(y_batch)\\nwith tf.Session()  as sess:\\n\\n    i = 0\\n    coord = tf.train.Coordinator()\\n    threads = tf.train.start_queue_runners(coord=coord)\\n\\n    try:\\n        while not coord.should_stop() and i<1:\\n            # just plot one batch size\\n            x, y = sess.run([x_batch, y_batch])\\n            for j in np.arange(BATCH_SIZE):\\n                print(y_batch)\\n                print(y)\\n            i+=1\\n    except tf.errors.OutOfRangeError:\\n        print('done!')\\n    finally:\\n        coord.request_stop()\\n    coord.join(threads)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "toYgfmOAjL-F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Demo (y = wx+b)"
      ]
    },
    {
      "metadata": {
        "id": "ZqOUVlNwjEin",
        "colab_type": "code",
        "outputId": "e6cc1020-ad08-471f-ae8a-e70801ddfdff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9393
        }
      },
      "cell_type": "code",
      "source": [
        "# _*_ coding: utf-8 _*_\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "\n",
        "BATCH_SIZE = 20\n",
        "\n",
        "TRAIN_TF_REDOCRD_FILE = 'train.tfrecords'\n",
        "TEST_TF_REDOCRD_FILE = 'test.tfrecords'\n",
        "\n",
        "MAX_STEPS = 500\n",
        "\n",
        "LOG_DIR = './log'\n",
        "MODELS_DIR = LOG_DIR + '/models/test_model.ckpt'\n",
        "\n",
        "\n",
        "#input\n",
        "with tf.name_scope('input'):\n",
        "    with tf.name_scope('x'):\n",
        "        x = tf.placeholder(tf.float32, shape = (BATCH_SIZE,), name = \"x\")\n",
        "        #print(x)\n",
        "    with tf.name_scope('y_'):\n",
        "        y_ = tf.placeholder(tf.float32, shape = (BATCH_SIZE,), name = \"y_\")\n",
        "\n",
        "        \n",
        "# layer\n",
        "with tf.name_scope('layer'):\n",
        "    with tf.name_scope('weights'):\n",
        "        ###对权进行赋值 在-1到1之间随机数\n",
        "        Weights = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
        "        tf.summary.histogram('Weights' ,Weights)\n",
        "    with tf.name_scope('biases'):\n",
        "        #初始偏差为零\n",
        "        biases = tf.Variable(tf.zeros([1]))\n",
        "        tf.summary.histogram('biases' ,biases)\n",
        "        \n",
        "with tf.name_scope('Result'):\n",
        "    #权值与x相乘并加偏差\n",
        "    #y = Weights * x + biases\n",
        "    y = tf.add(tf.multiply(Weights,x),biases,name = 'out')\n",
        "\n",
        "#Mean Squared Error)\n",
        "with tf.name_scope('Mean_Squared_Error'):\n",
        "    #方差，(y-y_)平方，求和，取均值\n",
        "    loss = tf.reduce_mean(tf.square(y-y_),name='loss')\n",
        "    tf.summary.scalar('loss', loss)\n",
        "    \n",
        "#Optimizer\n",
        "with tf.name_scope('train'):\n",
        "    #定义梯度下降法优化函数优化，步长为0.5\n",
        "    optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
        "    #tf.summary.scalar('optimizer', optimizer)\n",
        "    train_step = optimizer.minimize(loss)\n",
        "\n",
        "  \n",
        "def feed_dict(train,batch_sieze):\n",
        "    #xs, ys =x_data[0], x_data[1]\n",
        "    if train:\n",
        "      data = read_and_decode_two(TRAIN_TF_REDOCRD_FILE,batch_sieze)\n",
        "    else :\n",
        "      data = read_and_decode_two(TEST_TF_REDOCRD_FILE,batch_sieze)\n",
        "\n",
        "    next_element = data.make_one_shot_iterator().get_next()\n",
        "\n",
        "    return next_element\n",
        "\n",
        "#Xs,Ys = feed_dict(True,BATCH_SIZE)\n",
        "\n",
        "merged = tf.summary.merge_all()\n",
        "\n",
        "step = 0\n",
        "\n",
        "#session\n",
        "with  tf.Session() as sess:\n",
        "  \n",
        "    init = tf.global_variables_initializer()\n",
        "    \n",
        "    #create FileWriter and loadd graph\n",
        "    train_writer = tf.summary.FileWriter(LOG_DIR+'/train', sess.graph)\n",
        "    test_writer = tf.summary.FileWriter(LOG_DIR+'/test')\n",
        "    \n",
        "    sess.run(init)\n",
        "    \n",
        "    plt.figure(figsize=(10, 10), dpi=80)\n",
        "    plt.ion()\n",
        "\n",
        "    #Save\n",
        "    saver = tf.train.Saver()\n",
        "    \n",
        "    coord = tf.train.Coordinator()\n",
        "    threads = tf.train.start_queue_runners(coord=coord)\n",
        "    \n",
        "    try:\n",
        "        while not coord.should_stop() and  step <= MAX_STEPS:\n",
        "          \n",
        "            plt.title(\" Diagram.\")\n",
        "            plt.xlabel(\"x_data\")\n",
        "            plt.ylabel(\"y_\")\n",
        "            \n",
        "            if step % 10 == 0:\n",
        "              x_data ,y_data = sess.run(fetches=feed_dict(False,BATCH_SIZE))\n",
        "              summary,y_re,loss_value, _ = sess.run([merged,y,loss,train_step],feed_dict={x:x_data,y_:y_data})\n",
        "              test_writer.add_summary(summary, step)\n",
        "              print(\"At %d  step(s), loss is %g, weight is %g , bias is %g\" %(step, loss_value,sess.run(Weights),sess.run(biases)))\n",
        "            else:\n",
        "              if step % 100 == 99:\n",
        "                    x_data ,y_data = sess.run(fetches=feed_dict(True,BATCH_SIZE))\n",
        "                    run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
        "                    run_metadata = tf.RunMetadata()\n",
        "                    summary,y_re,loss_value, _ = sess.run([merged,y,loss,train_step],feed_dict={x:x_data,y_:y_data},options=run_options,run_metadata=run_metadata)\n",
        "                    train_writer.add_run_metadata(run_metadata, 'step%03d' % step)\n",
        "                    train_writer.add_summary(summary, step)\n",
        "                    print('Adding run metadata fro ', step)\n",
        "                    print(\"After %d  step(s), loss is %g, weight is %g , bias is %g\" %(step, loss_value,sess.run(Weights),sess.run(biases)))\n",
        "                    saver.save(sess,MODELS_DIR, global_step=step)\n",
        "              else:\n",
        "                  x_data ,y_data = sess.run(fetches=feed_dict(True,BATCH_SIZE))\n",
        "                  summary,y_re,loss_value, _ = sess.run([merged,y,loss,train_step],feed_dict={x:x_data,y_:y_data})\n",
        "                  train_writer.add_summary(summary, step)\n",
        "            \n",
        "            if step % 50 == 0:\n",
        "                print(\"After %d  step(s), loss is %g, weight is %g , bias is %g\" %(step, loss_value,sess.run(Weights),sess.run(biases)))\n",
        "                \n",
        "            plt.plot(x_data,y_data,'ro',color='b',linewidth=0.5)\n",
        "            if step % 10 == 0:\n",
        "                plt.plot(x_data,y_re,'ro', color='g',linewidth=0.5)\n",
        "\n",
        "            step += 1\n",
        "            \n",
        "            #if step > MAX_STEPS :\n",
        "            #    freeze_graph(MODELS_DIR)\n",
        "\n",
        "    except tf.errors.OutOfRangeError:\n",
        "        print('done!')\n",
        "    finally:\n",
        "        coord.request_stop()\n",
        "    coord.join(threads)\n",
        "\n",
        "    plt.ioff()\n",
        "    plt.show()\n",
        "    \n",
        "    #close FileWriter\n",
        "    train_writer.close()\n",
        "    test_writer.close()\n",
        "\n",
        "print(\"Done !!!\")\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-dcf188767946>:95: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
            "At 0  step(s), loss is 0.385886, weight is -0.024411 , bias is 0.111662\n",
            "After 1  step(s), loss is 0.20721, weight is 0.00800843 , bias is 0.187478\n",
            "After 2  step(s), loss is 0.147209, weight is 0.03269 , bias is 0.245526\n",
            "After 3  step(s), loss is 0.112097, weight is 0.0514543 , bias is 0.289982\n",
            "After 4  step(s), loss is 0.0915486, weight is 0.0656938 , bias is 0.324039\n",
            "After 5  step(s), loss is 0.079523, weight is 0.0764739 , bias is 0.350141\n",
            "After 6  step(s), loss is 0.0724847, weight is 0.0846094 , bias is 0.370157\n",
            "After 7  step(s), loss is 0.0683649, weight is 0.0907236 , bias is 0.385516\n",
            "After 8  step(s), loss is 0.065953, weight is 0.0952933 , bias is 0.397311\n",
            "After 9  step(s), loss is 0.0645405, weight is 0.0986832 , bias is 0.406381\n",
            "At 10  step(s), loss is 0.0857604, weight is 0.10151 , bias is 0.423298\n",
            "After 11  step(s), loss is 0.0627878, weight is 0.102497 , bias is 0.426671\n",
            "After 12  step(s), loss is 0.0626786, weight is 0.103162 , bias is 0.42929\n",
            "After 13  step(s), loss is 0.0626139, weight is 0.103583 , bias is 0.431332\n",
            "After 14  step(s), loss is 0.0625754, weight is 0.103819 , bias is 0.432931\n",
            "After 15  step(s), loss is 0.0625521, weight is 0.103914 , bias is 0.434192\n",
            "After 16  step(s), loss is 0.0625378, weight is 0.103903 , bias is 0.435193\n",
            "After 17  step(s), loss is 0.0625288, weight is 0.103812 , bias is 0.435995\n",
            "After 18  step(s), loss is 0.0625229, weight is 0.103662 , bias is 0.436643\n",
            "After 19  step(s), loss is 0.0625188, weight is 0.103467 , bias is 0.437174\n",
            "At 20  step(s), loss is 0.0814885, weight is 0.103575 , bias is 0.447547\n",
            "After 21  step(s), loss is 0.0625788, weight is 0.102509 , bias is 0.445904\n",
            "After 22  step(s), loss is 0.0625449, weight is 0.101629 , bias is 0.444675\n",
            "After 23  step(s), loss is 0.0625246, weight is 0.100892 , bias is 0.443763\n",
            "After 24  step(s), loss is 0.0625124, weight is 0.100265 , bias is 0.443093\n",
            "After 25  step(s), loss is 0.0625048, weight is 0.0997248 , bias is 0.442607\n",
            "After 26  step(s), loss is 0.0625001, weight is 0.0992508 , bias is 0.442261\n",
            "After 27  step(s), loss is 0.0624969, weight is 0.0988286 , bias is 0.442023\n",
            "After 28  step(s), loss is 0.0624948, weight is 0.098447 , bias is 0.441866\n",
            "After 29  step(s), loss is 0.0624932, weight is 0.0980974 , bias is 0.441771\n",
            "At 30  step(s), loss is 0.0810257, weight is 0.0980963 , bias is 0.451658\n",
            "After 31  step(s), loss is 0.0625944, weight is 0.0969779 , bias is 0.449633\n",
            "After 32  step(s), loss is 0.0625471, weight is 0.096079 , bias is 0.448103\n",
            "After 33  step(s), loss is 0.0625193, weight is 0.0953486 , bias is 0.446951\n",
            "After 34  step(s), loss is 0.0625028, weight is 0.0947479 , bias is 0.446088\n",
            "After 35  step(s), loss is 0.062493, weight is 0.094247 , bias is 0.445446\n",
            "After 36  step(s), loss is 0.0624871, weight is 0.0938232 , bias is 0.444973\n",
            "After 37  step(s), loss is 0.0624835, weight is 0.0934589 , bias is 0.444628\n",
            "After 38  step(s), loss is 0.0624812, weight is 0.0931408 , bias is 0.444382\n",
            "After 39  step(s), loss is 0.0624798, weight is 0.0928586 , bias is 0.44421\n",
            "At 40  step(s), loss is 0.0807868, weight is 0.0929159 , bias is 0.454032\n",
            "After 41  step(s), loss is 0.0625871, weight is 0.0918699 , bias is 0.451948\n",
            "After 42  step(s), loss is 0.0625391, weight is 0.0910445 , bias is 0.450366\n",
            "After 43  step(s), loss is 0.062511, weight is 0.0903882 , bias is 0.449166\n",
            "After 44  step(s), loss is 0.0624944, weight is 0.0898616 , bias is 0.448259\n",
            "After 45  step(s), loss is 0.0624847, weight is 0.0894347 , bias is 0.447575\n",
            "After 46  step(s), loss is 0.062479, weight is 0.0890843 , bias is 0.447063\n",
            "After 47  step(s), loss is 0.0624756, weight is 0.0887929 , bias is 0.446681\n",
            "After 48  step(s), loss is 0.0624735, weight is 0.088547 , bias is 0.446399\n",
            "After 49  step(s), loss is 0.0624723, weight is 0.0883363 , bias is 0.446193\n",
            "At 50  step(s), loss is 0.0805964, weight is 0.0884538 , bias is 0.455983\n",
            "After 51  step(s), loss is 0.0625829, weight is 0.0874778 , bias is 0.453868\n",
            "After 52  step(s), loss is 0.062535, weight is 0.0867213 , bias is 0.452254\n",
            "After 53  step(s), loss is 0.062507, weight is 0.086133 , bias is 0.451024\n",
            "After 54  step(s), loss is 0.0624906, weight is 0.0856733 , bias is 0.450087\n",
            "After 55  step(s), loss is 0.062481, weight is 0.0853123 , bias is 0.449374\n",
            "After 56  step(s), loss is 0.0624753, weight is 0.0850269 , bias is 0.448833\n",
            "After 57  step(s), loss is 0.062472, weight is 0.0847994 , bias is 0.448423\n",
            "After 58  step(s), loss is 0.0624701, weight is 0.0846165 , bias is 0.448113\n",
            "After 59  step(s), loss is 0.062469, weight is 0.0844677 , bias is 0.44788\n",
            "At 60  step(s), loss is 0.0804369, weight is 0.0846374 , bias is 0.457645\n",
            "After 61  step(s), loss is 0.0625822, weight is 0.0837218 , bias is 0.455504\n",
            "After 62  step(s), loss is 0.0625344, weight is 0.0830247 , bias is 0.453865\n",
            "After 63  step(s), loss is 0.0625064, weight is 0.0824947 , bias is 0.452609\n",
            "After 64  step(s), loss is 0.06249, weight is 0.0820926 , bias is 0.451647\n",
            "After 65  step(s), loss is 0.0624804, weight is 0.0817881 , bias is 0.45091\n",
            "After 66  step(s), loss is 0.0624748, weight is 0.0815583 , bias is 0.450345\n",
            "After 67  step(s), loss is 0.0624715, weight is 0.0813856 , bias is 0.449911\n",
            "After 68  step(s), loss is 0.0624696, weight is 0.0812565 , bias is 0.449578\n",
            "After 69  step(s), loss is 0.0624684, weight is 0.0811608 , bias is 0.449322\n",
            "At 70  step(s), loss is 0.0803026, weight is 0.0813751 , bias is 0.459066\n",
            "After 71  step(s), loss is 0.0625838, weight is 0.0805112 , bias is 0.456903\n",
            "After 72  step(s), loss is 0.0625359, weight is 0.0798649 , bias is 0.455241\n",
            "After 73  step(s), loss is 0.0625078, weight is 0.0793849 , bias is 0.453964\n",
            "After 74  step(s), loss is 0.0624914, weight is 0.0790318 , bias is 0.452981\n",
            "After 75  step(s), loss is 0.0624818, weight is 0.0787757 , bias is 0.452223\n",
            "After 76  step(s), loss is 0.0624761, weight is 0.0785935 , bias is 0.451638\n",
            "After 77  step(s), loss is 0.0624728, weight is 0.0784676 , bias is 0.451183\n",
            "After 78  step(s), loss is 0.0624708, weight is 0.0783846 , bias is 0.45083\n",
            "After 79  step(s), loss is 0.0624697, weight is 0.0783341 , bias is 0.450554\n",
            "At 80  step(s), loss is 0.0801893, weight is 0.0785867 , bias is 0.46028\n",
            "After 81  step(s), loss is 0.0625867, weight is 0.0777668 , bias is 0.458098\n",
            "After 82  step(s), loss is 0.0625387, weight is 0.077164 , bias is 0.456418\n",
            "After 83  step(s), loss is 0.0625106, weight is 0.0767267 , bias is 0.455123\n",
            "After 84  step(s), loss is 0.0624941, weight is 0.0764156 , bias is 0.454122\n",
            "After 85  step(s), loss is 0.0624844, weight is 0.0762008 , bias is 0.453346\n",
            "After 86  step(s), loss is 0.0624786, weight is 0.0760593 , bias is 0.452742\n",
            "After 87  step(s), loss is 0.0624752, weight is 0.0759734 , bias is 0.452271\n",
            "After 88  step(s), loss is 0.0624732, weight is 0.0759298 , bias is 0.451901\n",
            "After 89  step(s), loss is 0.0624719, weight is 0.0759181 , bias is 0.451608\n",
            "At 90  step(s), loss is 0.0800934, weight is 0.0762032 , bias is 0.461318\n",
            "After 91  step(s), loss is 0.0625903, weight is 0.0754212 , bias is 0.459119\n",
            "After 92  step(s), loss is 0.0625422, weight is 0.0748554 , bias is 0.457424\n",
            "After 93  step(s), loss is 0.062514, weight is 0.0744546 , bias is 0.456113\n",
            "After 94  step(s), loss is 0.0624974, weight is 0.0741794 , bias is 0.455096\n",
            "After 95  step(s), loss is 0.0624876, weight is 0.074 , bias is 0.454305\n",
            "After 96  step(s), loss is 0.0624817, weight is 0.0738932 , bias is 0.453687\n",
            "After 97  step(s), loss is 0.0624782, weight is 0.0738415 , bias is 0.4532\n",
            "After 98  step(s), loss is 0.0624761, weight is 0.0738315 , bias is 0.452815\n",
            "Adding run metadata fro  99\n",
            "After 99  step(s), loss is 0.0624748, weight is 0.0738529 , bias is 0.452508\n",
            "At 100  step(s), loss is 0.0800122, weight is 0.074166 , bias is 0.462205\n",
            "After 101  step(s), loss is 0.0625943, weight is 0.0734161 , bias is 0.459993\n",
            "After 102  step(s), loss is 0.0625461, weight is 0.0728821 , bias is 0.458284\n",
            "After 103  step(s), loss is 0.0625177, weight is 0.0725125 , bias is 0.456959\n",
            "After 104  step(s), loss is 0.062501, weight is 0.072268 , bias is 0.455929\n",
            "After 105  step(s), loss is 0.0624911, weight is 0.0721187 , bias is 0.455125\n",
            "After 106  step(s), loss is 0.0624851, weight is 0.0720416 , bias is 0.454494\n",
            "After 107  step(s), loss is 0.0624815, weight is 0.0720192 , bias is 0.453995\n",
            "After 108  step(s), loss is 0.0624793, weight is 0.072038 , bias is 0.453597\n",
            "After 109  step(s), loss is 0.0624779, weight is 0.0720877 , bias is 0.453278\n",
            "At 110  step(s), loss is 0.0799434, weight is 0.0724246 , bias is 0.462963\n",
            "After 111  step(s), loss is 0.0625983, weight is 0.0717023 , bias is 0.460739\n",
            "After 112  step(s), loss is 0.06255, weight is 0.0711954 , bias is 0.459018\n",
            "After 113  step(s), loss is 0.0625215, weight is 0.0708524 , bias is 0.457683\n",
            "After 114  step(s), loss is 0.0625047, weight is 0.0706342 , bias is 0.456641\n",
            "After 115  step(s), loss is 0.0624946, weight is 0.0705107 , bias is 0.455826\n",
            "After 116  step(s), loss is 0.0624886, weight is 0.070459 , bias is 0.455184\n",
            "After 117  step(s), loss is 0.0624849, weight is 0.0704616 , bias is 0.454674\n",
            "After 118  step(s), loss is 0.0624825, weight is 0.0705049 , bias is 0.454266\n",
            "After 119  step(s), loss is 0.062481, weight is 0.0705789 , bias is 0.453936\n",
            "At 120  step(s), loss is 0.0798849, weight is 0.0709362 , bias is 0.463611\n",
            "After 121  step(s), loss is 0.0626021, weight is 0.0702375 , bias is 0.461377\n",
            "After 122  step(s), loss is 0.0625537, weight is 0.0697537 , bias is 0.459647\n",
            "After 123  step(s), loss is 0.0625251, weight is 0.0694335 , bias is 0.458301\n",
            "After 124  step(s), loss is 0.0625082, weight is 0.0692377 , bias is 0.45725\n",
            "After 125  step(s), loss is 0.062498, weight is 0.0691363 , bias is 0.456425\n",
            "After 126  step(s), loss is 0.0624919, weight is 0.0691063 , bias is 0.455773\n",
            "After 127  step(s), loss is 0.0624881, weight is 0.0691302 , bias is 0.455254\n",
            "After 128  step(s), loss is 0.0624856, weight is 0.0691946 , bias is 0.454837\n",
            "After 129  step(s), loss is 0.062484, weight is 0.0692892 , bias is 0.454498\n",
            "At 130  step(s), loss is 0.0798353, weight is 0.0696639 , bias is 0.464165\n",
            "After 131  step(s), loss is 0.0626058, weight is 0.0689853 , bias is 0.461923\n",
            "After 132  step(s), loss is 0.0625572, weight is 0.0685214 , bias is 0.460183\n",
            "After 133  step(s), loss is 0.0625286, weight is 0.0682207 , bias is 0.458829\n",
            "After 134  step(s), loss is 0.0625115, weight is 0.0680441 , bias is 0.45777\n",
            "After 135  step(s), loss is 0.0625013, weight is 0.0679615 , bias is 0.456937\n",
            "After 136  step(s), loss is 0.062495, weight is 0.06795 , bias is 0.456277\n",
            "After 137  step(s), loss is 0.0624911, weight is 0.0679922 , bias is 0.45575\n",
            "After 138  step(s), loss is 0.0624886, weight is 0.0680745 , bias is 0.455325\n",
            "After 139  step(s), loss is 0.0624868, weight is 0.0681868 , bias is 0.454979\n",
            "At 140  step(s), loss is 0.079793, weight is 0.0685764 , bias is 0.464638\n",
            "After 141  step(s), loss is 0.0626091, weight is 0.0679151 , bias is 0.462389\n",
            "After 142  step(s), loss is 0.0625605, weight is 0.067468 , bias is 0.460642\n",
            "After 143  step(s), loss is 0.0625317, weight is 0.067184 , bias is 0.459281\n",
            "After 144  step(s), loss is 0.0625146, weight is 0.0670237 , bias is 0.458215\n",
            "After 145  step(s), loss is 0.0625042, weight is 0.0669573 , bias is 0.457375\n",
            "After 146  step(s), loss is 0.0624979, weight is 0.0669617 , bias is 0.456708\n",
            "After 147  step(s), loss is 0.0624939, weight is 0.0670195 , bias is 0.456174\n",
            "After 148  step(s), loss is 0.0624912, weight is 0.0671172 , bias is 0.455743\n",
            "After 149  step(s), loss is 0.0624894, weight is 0.0672446 , bias is 0.45539\n",
            "At 150  step(s), loss is 0.0797571, weight is 0.0676469 , bias is 0.465043\n",
            "After 151  step(s), loss is 0.0626121, weight is 0.0670002 , bias is 0.462787\n",
            "After 152  step(s), loss is 0.0625634, weight is 0.0665677 , bias is 0.461035\n",
            "After 153  step(s), loss is 0.0625346, weight is 0.0662979 , bias is 0.459667\n",
            "After 154  step(s), loss is 0.0625173, weight is 0.0661516 , bias is 0.458595\n",
            "After 155  step(s), loss is 0.0625069, weight is 0.066099 , bias is 0.457749\n",
            "After 156  step(s), loss is 0.0625005, weight is 0.0661169 , bias is 0.457076\n",
            "After 157  step(s), loss is 0.0624964, weight is 0.066188 , bias is 0.456537\n",
            "After 158  step(s), loss is 0.0624937, weight is 0.0662988 , bias is 0.4561\n",
            "After 159  step(s), loss is 0.0624918, weight is 0.0664392 , bias is 0.455741\n",
            "At 160  step(s), loss is 0.0797265, weight is 0.0668524 , bias is 0.465389\n",
            "After 161  step(s), loss is 0.0626149, weight is 0.0662183 , bias is 0.463128\n",
            "After 162  step(s), loss is 0.0625661, weight is 0.0657981 , bias is 0.46137\n",
            "After 163  step(s), loss is 0.0625371, weight is 0.0655405 , bias is 0.459997\n",
            "After 164  step(s), loss is 0.0625198, weight is 0.0654062 , bias is 0.45892\n",
            "After 165  step(s), loss is 0.0625093, weight is 0.0653653 , bias is 0.458069\n",
            "After 166  step(s), loss is 0.0625028, weight is 0.0653948 , bias is 0.457391\n",
            "After 167  step(s), loss is 0.0624987, weight is 0.0654773 , bias is 0.456847\n",
            "After 168  step(s), loss is 0.0624959, weight is 0.0655994 , bias is 0.456404\n",
            "After 169  step(s), loss is 0.0624939, weight is 0.0657507 , bias is 0.456041\n",
            "At 170  step(s), loss is 0.0797004, weight is 0.0661732 , bias is 0.465685\n",
            "After 171  step(s), loss is 0.0626173, weight is 0.0655499 , bias is 0.463419\n",
            "After 172  step(s), loss is 0.0625684, weight is 0.0651403 , bias is 0.461656\n",
            "After 173  step(s), loss is 0.0625394, weight is 0.064893 , bias is 0.460279\n",
            "After 174  step(s), loss is 0.062522, weight is 0.064769 , bias is 0.459198\n",
            "After 175  step(s), loss is 0.0625115, weight is 0.0647382 , bias is 0.458342\n",
            "After 176  step(s), loss is 0.0625049, weight is 0.0647776 , bias is 0.45766\n",
            "After 177  step(s), loss is 0.0625007, weight is 0.0648699 , bias is 0.457112\n",
            "After 178  step(s), loss is 0.0624978, weight is 0.0650015 , bias is 0.456665\n",
            "After 179  step(s), loss is 0.0624958, weight is 0.0651623 , bias is 0.456297\n",
            "At 180  step(s), loss is 0.0796782, weight is 0.0655927 , bias is 0.465937\n",
            "After 181  step(s), loss is 0.0626194, weight is 0.0649786 , bias is 0.463668\n",
            "After 182  step(s), loss is 0.0625705, weight is 0.064578 , bias is 0.461901\n",
            "After 183  step(s), loss is 0.0625414, weight is 0.0643397 , bias is 0.460521\n",
            "After 184  step(s), loss is 0.062524, weight is 0.0642244 , bias is 0.459435\n",
            "After 185  step(s), loss is 0.0625133, weight is 0.0642021 , bias is 0.458576\n",
            "After 186  step(s), loss is 0.0625067, weight is 0.0642501 , bias is 0.45789\n",
            "After 187  step(s), loss is 0.0625024, weight is 0.0643506 , bias is 0.457338\n",
            "After 188  step(s), loss is 0.0624995, weight is 0.0644905 , bias is 0.456888\n",
            "After 189  step(s), loss is 0.0624975, weight is 0.0646593 , bias is 0.456517\n",
            "At 190  step(s), loss is 0.0796592, weight is 0.0650966 , bias is 0.466153\n",
            "After 191  step(s), loss is 0.0626213, weight is 0.0644903 , bias is 0.463881\n",
            "After 192  step(s), loss is 0.0625723, weight is 0.0640974 , bias is 0.462111\n",
            "After 193  step(s), loss is 0.0625432, weight is 0.0638667 , bias is 0.460727\n",
            "After 194  step(s), loss is 0.0625257, weight is 0.0637589 , bias is 0.459638\n",
            "After 195  step(s), loss is 0.062515, weight is 0.063744 , bias is 0.458775\n",
            "After 196  step(s), loss is 0.0625083, weight is 0.0637991 , bias is 0.458087\n",
            "After 197  step(s), loss is 0.062504, weight is 0.0639068 , bias is 0.457531\n",
            "After 198  step(s), loss is 0.0625011, weight is 0.0640536 , bias is 0.457078\n",
            "Adding run metadata fro  199\n",
            "After 199  step(s), loss is 0.0624989, weight is 0.0642294 , bias is 0.456704\n",
            "At 200  step(s), loss is 0.079643, weight is 0.0646724 , bias is 0.466338\n",
            "After 201  step(s), loss is 0.0626229, weight is 0.0640729 , bias is 0.464062\n",
            "After 202  step(s), loss is 0.0625739, weight is 0.0636866 , bias is 0.46229\n",
            "After 203  step(s), loss is 0.0625447, weight is 0.0634624 , bias is 0.460903\n",
            "After 204  step(s), loss is 0.0625272, weight is 0.0633609 , bias is 0.459811\n",
            "After 205  step(s), loss is 0.0625165, weight is 0.0633523 , bias is 0.458946\n",
            "After 206  step(s), loss is 0.0625097, weight is 0.0634137 , bias is 0.458255\n",
            "After 207  step(s), loss is 0.0625054, weight is 0.0635274 , bias is 0.457697\n",
            "After 208  step(s), loss is 0.0625024, weight is 0.0636803 , bias is 0.457241\n",
            "After 209  step(s), loss is 0.0625002, weight is 0.0638619 , bias is 0.456864\n",
            "At 210  step(s), loss is 0.0796292, weight is 0.0643099 , bias is 0.466496\n",
            "After 211  step(s), loss is 0.0626244, weight is 0.0637161 , bias is 0.464218\n",
            "After 212  step(s), loss is 0.0625753, weight is 0.0633355 , bias is 0.462443\n",
            "After 213  step(s), loss is 0.0625461, weight is 0.0631168 , bias is 0.461053\n",
            "After 214  step(s), loss is 0.0625285, weight is 0.0630208 , bias is 0.45996\n",
            "After 215  step(s), loss is 0.0625177, weight is 0.0630176 , bias is 0.459092\n",
            "After 216  step(s), loss is 0.062511, weight is 0.0630842 , bias is 0.458398\n",
            "After 217  step(s), loss is 0.0625065, weight is 0.0632032 , bias is 0.457838\n",
            "After 218  step(s), loss is 0.0625035, weight is 0.0633611 , bias is 0.45738\n",
            "After 219  step(s), loss is 0.0625013, weight is 0.0635478 , bias is 0.457001\n",
            "At 220  step(s), loss is 0.0796175, weight is 0.0640001 , bias is 0.466631\n",
            "After 221  step(s), loss is 0.0626256, weight is 0.0634111 , bias is 0.464351\n",
            "After 222  step(s), loss is 0.0625765, weight is 0.0630353 , bias is 0.462574\n",
            "After 223  step(s), loss is 0.0625473, weight is 0.0628214 , bias is 0.461182\n",
            "After 224  step(s), loss is 0.0625296, weight is 0.0627301 , bias is 0.460086\n",
            "After 225  step(s), loss is 0.0625188, weight is 0.0627315 , bias is 0.459217\n",
            "After 226  step(s), loss is 0.062512, weight is 0.0628026 , bias is 0.458521\n",
            "After 227  step(s), loss is 0.0625076, weight is 0.062926 , bias is 0.457959\n",
            "After 228  step(s), loss is 0.0625045, weight is 0.0630883 , bias is 0.457499\n",
            "After 229  step(s), loss is 0.0625023, weight is 0.0632793 , bias is 0.457118\n",
            "At 230  step(s), loss is 0.0796074, weight is 0.0637352 , bias is 0.466746\n",
            "After 231  step(s), loss is 0.0626267, weight is 0.0631505 , bias is 0.464464\n",
            "After 232  step(s), loss is 0.0625776, weight is 0.0627788 , bias is 0.462685\n",
            "After 233  step(s), loss is 0.0625483, weight is 0.0625689 , bias is 0.461292\n",
            "After 234  step(s), loss is 0.0625306, weight is 0.0624816 , bias is 0.460195\n",
            "After 235  step(s), loss is 0.0625198, weight is 0.0624869 , bias is 0.459323\n",
            "After 236  step(s), loss is 0.0625129, weight is 0.0625619 , bias is 0.458626\n",
            "After 237  step(s), loss is 0.0625085, weight is 0.0626891 , bias is 0.458062\n",
            "After 238  step(s), loss is 0.0625054, weight is 0.0628552 , bias is 0.457601\n",
            "After 239  step(s), loss is 0.0625031, weight is 0.0630498 , bias is 0.457218\n",
            "At 240  step(s), loss is 0.0795988, weight is 0.0635088 , bias is 0.466845\n",
            "After 241  step(s), loss is 0.0626276, weight is 0.0629277 , bias is 0.464561\n",
            "After 242  step(s), loss is 0.0625785, weight is 0.0625595 , bias is 0.462781\n",
            "After 243  step(s), loss is 0.0625491, weight is 0.0623531 , bias is 0.461386\n",
            "After 244  step(s), loss is 0.0625315, weight is 0.0622692 , bias is 0.460287\n",
            "After 245  step(s), loss is 0.0625206, weight is 0.0622778 , bias is 0.459415\n",
            "After 246  step(s), loss is 0.0625137, weight is 0.0623562 , bias is 0.458716\n",
            "After 247  step(s), loss is 0.0625092, weight is 0.0624866 , bias is 0.45815\n",
            "After 248  step(s), loss is 0.0625061, weight is 0.0626559 , bias is 0.457688\n",
            "After 249  step(s), loss is 0.0625039, weight is 0.0628537 , bias is 0.457304\n",
            "At 250  step(s), loss is 0.0795915, weight is 0.0633153 , bias is 0.466929\n",
            "After 251  step(s), loss is 0.0626284, weight is 0.0627373 , bias is 0.464644\n",
            "After 252  step(s), loss is 0.0625793, weight is 0.0623721 , bias is 0.462862\n",
            "After 253  step(s), loss is 0.0625499, weight is 0.0621686 , bias is 0.461467\n",
            "After 254  step(s), loss is 0.0625322, weight is 0.0620877 , bias is 0.460366\n",
            "After 255  step(s), loss is 0.0625213, weight is 0.0620992 , bias is 0.459492\n",
            "After 256  step(s), loss is 0.0625144, weight is 0.0621803 , bias is 0.458792\n",
            "After 257  step(s), loss is 0.0625099, weight is 0.0623136 , bias is 0.458226\n",
            "After 258  step(s), loss is 0.0625068, weight is 0.0624855 , bias is 0.457762\n",
            "After 259  step(s), loss is 0.0625045, weight is 0.062686 , bias is 0.457377\n",
            "At 260  step(s), loss is 0.0795853, weight is 0.0631499 , bias is 0.467001\n",
            "After 261  step(s), loss is 0.0626291, weight is 0.0625745 , bias is 0.464715\n",
            "After 262  step(s), loss is 0.0625799, weight is 0.0622119 , bias is 0.462932\n",
            "After 263  step(s), loss is 0.0625506, weight is 0.062011 , bias is 0.461535\n",
            "After 264  step(s), loss is 0.0625328, weight is 0.0619325 , bias is 0.460434\n",
            "After 265  step(s), loss is 0.0625219, weight is 0.0619465 , bias is 0.459559\n",
            "After 266  step(s), loss is 0.062515, weight is 0.06203 , bias is 0.458858\n",
            "After 267  step(s), loss is 0.0625105, weight is 0.0621656 , bias is 0.45829\n",
            "After 268  step(s), loss is 0.0625073, weight is 0.0623399 , bias is 0.457826\n",
            "After 269  step(s), loss is 0.062505, weight is 0.0625427 , bias is 0.45744\n",
            "At 270  step(s), loss is 0.0795799, weight is 0.0630086 , bias is 0.467063\n",
            "After 271  step(s), loss is 0.0626297, weight is 0.0624354 , bias is 0.464776\n",
            "After 272  step(s), loss is 0.0625805, weight is 0.062075 , bias is 0.462992\n",
            "After 273  step(s), loss is 0.0625511, weight is 0.0618762 , bias is 0.461594\n",
            "After 274  step(s), loss is 0.0625334, weight is 0.0617999 , bias is 0.460492\n",
            "After 275  step(s), loss is 0.0625224, weight is 0.0618159 , bias is 0.459616\n",
            "After 276  step(s), loss is 0.0625155, weight is 0.0619015 , bias is 0.458914\n",
            "After 277  step(s), loss is 0.062511, weight is 0.0620392 , bias is 0.458346\n",
            "After 278  step(s), loss is 0.0625078, weight is 0.0622155 , bias is 0.45788\n",
            "After 279  step(s), loss is 0.0625055, weight is 0.0624203 , bias is 0.457493\n",
            "At 280  step(s), loss is 0.0795753, weight is 0.0628877 , bias is 0.467115\n",
            "After 281  step(s), loss is 0.0626302, weight is 0.0623164 , bias is 0.464827\n",
            "After 282  step(s), loss is 0.062581, weight is 0.0619579 , bias is 0.463043\n",
            "After 283  step(s), loss is 0.0625516, weight is 0.061761 , bias is 0.461644\n",
            "After 284  step(s), loss is 0.0625338, weight is 0.0616865 , bias is 0.460541\n",
            "After 285  step(s), loss is 0.0625229, weight is 0.0617043 , bias is 0.459664\n",
            "After 286  step(s), loss is 0.062516, weight is 0.0617917 , bias is 0.458962\n",
            "After 287  step(s), loss is 0.0625114, weight is 0.0619311 , bias is 0.458393\n",
            "After 288  step(s), loss is 0.0625082, weight is 0.0621091 , bias is 0.457926\n",
            "After 289  step(s), loss is 0.0625059, weight is 0.0623155 , bias is 0.457539\n",
            "At 290  step(s), loss is 0.0795714, weight is 0.0627844 , bias is 0.46716\n",
            "After 291  step(s), loss is 0.0626307, weight is 0.0622148 , bias is 0.464872\n",
            "After 292  step(s), loss is 0.0625814, weight is 0.0618579 , bias is 0.463087\n",
            "After 293  step(s), loss is 0.062552, weight is 0.0616626 , bias is 0.461687\n",
            "After 294  step(s), loss is 0.0625342, weight is 0.0615896 , bias is 0.460583\n",
            "After 295  step(s), loss is 0.0625233, weight is 0.0616089 , bias is 0.459706\n",
            "After 296  step(s), loss is 0.0625163, weight is 0.0616978 , bias is 0.459003\n",
            "After 297  step(s), loss is 0.0625118, weight is 0.0618387 , bias is 0.458433\n",
            "After 298  step(s), loss is 0.0625086, weight is 0.0620182 , bias is 0.457966\n",
            "Adding run metadata fro  299\n",
            "After 299  step(s), loss is 0.0625062, weight is 0.062226 , bias is 0.457578\n",
            "At 300  step(s), loss is 0.0795681, weight is 0.0626962 , bias is 0.467199\n",
            "After 301  step(s), loss is 0.062631, weight is 0.0621279 , bias is 0.464909\n",
            "After 302  step(s), loss is 0.0625818, weight is 0.0617724 , bias is 0.463124\n",
            "After 303  step(s), loss is 0.0625524, weight is 0.0615784 , bias is 0.461724\n",
            "After 304  step(s), loss is 0.0625346, weight is 0.0615067 , bias is 0.460619\n",
            "After 305  step(s), loss is 0.0625236, weight is 0.0615274 , bias is 0.459742\n",
            "After 306  step(s), loss is 0.0625167, weight is 0.0616176 , bias is 0.459038\n",
            "After 307  step(s), loss is 0.0625121, weight is 0.0617597 , bias is 0.458467\n",
            "After 308  step(s), loss is 0.0625089, weight is 0.0619404 , bias is 0.458\n",
            "After 309  step(s), loss is 0.0625065, weight is 0.0621496 , bias is 0.457611\n",
            "At 310  step(s), loss is 0.0795652, weight is 0.0626207 , bias is 0.467231\n",
            "After 311  step(s), loss is 0.0626314, weight is 0.0620536 , bias is 0.464942\n",
            "After 312  step(s), loss is 0.0625821, weight is 0.0616993 , bias is 0.463156\n",
            "After 313  step(s), loss is 0.0625527, weight is 0.0615065 , bias is 0.461755\n",
            "After 314  step(s), loss is 0.0625349, weight is 0.0614359 , bias is 0.46065\n",
            "After 315  step(s), loss is 0.0625239, weight is 0.0614577 , bias is 0.459772\n",
            "After 316  step(s), loss is 0.0625169, weight is 0.061549 , bias is 0.459068\n",
            "After 317  step(s), loss is 0.0625123, weight is 0.0616922 , bias is 0.458497\n",
            "After 318  step(s), loss is 0.0625091, weight is 0.061874 , bias is 0.458029\n",
            "After 319  step(s), loss is 0.0625068, weight is 0.0620842 , bias is 0.45764\n",
            "At 320  step(s), loss is 0.0795628, weight is 0.0625562 , bias is 0.46726\n",
            "After 321  step(s), loss is 0.0626317, weight is 0.0619901 , bias is 0.464969\n",
            "After 322  step(s), loss is 0.0625824, weight is 0.0616368 , bias is 0.463183\n",
            "After 323  step(s), loss is 0.0625529, weight is 0.061445 , bias is 0.461782\n",
            "After 324  step(s), loss is 0.0625351, weight is 0.0613754 , bias is 0.460677\n",
            "After 325  step(s), loss is 0.0625241, weight is 0.0613982 , bias is 0.459798\n",
            "After 326  step(s), loss is 0.0625172, weight is 0.0614904 , bias is 0.459093\n",
            "After 327  step(s), loss is 0.0625126, weight is 0.0616345 , bias is 0.458522\n",
            "After 328  step(s), loss is 0.0625094, weight is 0.0618172 , bias is 0.458053\n",
            "After 329  step(s), loss is 0.062507, weight is 0.0620283 , bias is 0.457664\n",
            "At 330  step(s), loss is 0.0795607, weight is 0.0625011 , bias is 0.467284\n",
            "After 331  step(s), loss is 0.0626319, weight is 0.0619359 , bias is 0.464993\n",
            "After 332  step(s), loss is 0.0625826, weight is 0.0615834 , bias is 0.463206\n",
            "After 333  step(s), loss is 0.0625532, weight is 0.0613924 , bias is 0.461805\n",
            "After 334  step(s), loss is 0.0625353, weight is 0.0613237 , bias is 0.460699\n",
            "After 335  step(s), loss is 0.0625244, weight is 0.0613473 , bias is 0.45982\n",
            "After 336  step(s), loss is 0.0625174, weight is 0.0614403 , bias is 0.459115\n",
            "After 337  step(s), loss is 0.0625128, weight is 0.0615852 , bias is 0.458543\n",
            "After 338  step(s), loss is 0.0625096, weight is 0.0617687 , bias is 0.458075\n",
            "After 339  step(s), loss is 0.0625072, weight is 0.0619805 , bias is 0.457685\n",
            "At 340  step(s), loss is 0.079559, weight is 0.0624539 , bias is 0.467304\n",
            "After 341  step(s), loss is 0.0626321, weight is 0.0618895 , bias is 0.465013\n",
            "After 342  step(s), loss is 0.0625828, weight is 0.0615377 , bias is 0.463226\n",
            "After 343  step(s), loss is 0.0625533, weight is 0.0613475 , bias is 0.461824\n",
            "After 344  step(s), loss is 0.0625355, weight is 0.0612794 , bias is 0.460718\n",
            "After 345  step(s), loss is 0.0625245, weight is 0.0613037 , bias is 0.459839\n",
            "After 346  step(s), loss is 0.0625176, weight is 0.0613974 , bias is 0.459134\n",
            "After 347  step(s), loss is 0.0625129, weight is 0.061543 , bias is 0.458562\n",
            "After 348  step(s), loss is 0.0625097, weight is 0.0617272 , bias is 0.458093\n",
            "After 349  step(s), loss is 0.0625073, weight is 0.0619397 , bias is 0.457703\n",
            "At 350  step(s), loss is 0.0795574, weight is 0.0624136 , bias is 0.467322\n",
            "After 351  step(s), loss is 0.0626323, weight is 0.0618498 , bias is 0.465031\n",
            "After 352  step(s), loss is 0.062583, weight is 0.0614987 , bias is 0.463243\n",
            "After 353  step(s), loss is 0.0625535, weight is 0.0613091 , bias is 0.461841\n",
            "After 354  step(s), loss is 0.0625357, weight is 0.0612416 , bias is 0.460735\n",
            "After 355  step(s), loss is 0.0625247, weight is 0.0612665 , bias is 0.459855\n",
            "After 356  step(s), loss is 0.0625177, weight is 0.0613608 , bias is 0.45915\n",
            "After 357  step(s), loss is 0.0625131, weight is 0.061507 , bias is 0.458578\n",
            "After 358  step(s), loss is 0.0625099, weight is 0.0616917 , bias is 0.458108\n",
            "After 359  step(s), loss is 0.0625075, weight is 0.0619047 , bias is 0.457718\n",
            "At 360  step(s), loss is 0.0795561, weight is 0.0623792 , bias is 0.467337\n",
            "After 361  step(s), loss is 0.0626324, weight is 0.0618159 , bias is 0.465045\n",
            "After 362  step(s), loss is 0.0625831, weight is 0.0614654 , bias is 0.463258\n",
            "After 363  step(s), loss is 0.0625537, weight is 0.0612762 , bias is 0.461855\n",
            "After 364  step(s), loss is 0.0625358, weight is 0.0612093 , bias is 0.460749\n",
            "After 365  step(s), loss is 0.0625248, weight is 0.0612347 , bias is 0.459869\n",
            "After 366  step(s), loss is 0.0625178, weight is 0.0613295 , bias is 0.459163\n",
            "After 367  step(s), loss is 0.0625132, weight is 0.0614762 , bias is 0.458591\n",
            "After 368  step(s), loss is 0.06251, weight is 0.0616614 , bias is 0.458121\n",
            "After 369  step(s), loss is 0.0625076, weight is 0.0618749 , bias is 0.457731\n",
            "At 370  step(s), loss is 0.079555, weight is 0.0623498 , bias is 0.467349\n",
            "After 371  step(s), loss is 0.0626325, weight is 0.061787 , bias is 0.465058\n",
            "After 372  step(s), loss is 0.0625832, weight is 0.0614369 , bias is 0.46327\n",
            "After 373  step(s), loss is 0.0625538, weight is 0.0612482 , bias is 0.461868\n",
            "After 374  step(s), loss is 0.0625359, weight is 0.0611817 , bias is 0.460761\n",
            "After 375  step(s), loss is 0.0625249, weight is 0.0612076 , bias is 0.459881\n",
            "After 376  step(s), loss is 0.0625179, weight is 0.0613028 , bias is 0.459175\n",
            "After 377  step(s), loss is 0.0625133, weight is 0.0614499 , bias is 0.458602\n",
            "After 378  step(s), loss is 0.0625101, weight is 0.0616355 , bias is 0.458133\n",
            "After 379  step(s), loss is 0.0625077, weight is 0.0618494 , bias is 0.457742\n",
            "At 380  step(s), loss is 0.0795541, weight is 0.0623246 , bias is 0.46736\n",
            "After 381  step(s), loss is 0.0626327, weight is 0.0617622 , bias is 0.465069\n",
            "After 382  step(s), loss is 0.0625833, weight is 0.0614125 , bias is 0.463281\n",
            "After 383  step(s), loss is 0.0625539, weight is 0.0612242 , bias is 0.461878\n",
            "After 384  step(s), loss is 0.062536, weight is 0.0611581 , bias is 0.460771\n",
            "After 385  step(s), loss is 0.062525, weight is 0.0611843 , bias is 0.459891\n",
            "After 386  step(s), loss is 0.062518, weight is 0.0612799 , bias is 0.459185\n",
            "After 387  step(s), loss is 0.0625134, weight is 0.0614274 , bias is 0.458612\n",
            "After 388  step(s), loss is 0.0625102, weight is 0.0616133 , bias is 0.458142\n",
            "After 389  step(s), loss is 0.0625078, weight is 0.0618276 , bias is 0.457751\n",
            "At 390  step(s), loss is 0.0795533, weight is 0.0623031 , bias is 0.46737\n",
            "After 391  step(s), loss is 0.0626328, weight is 0.0617411 , bias is 0.465078\n",
            "After 392  step(s), loss is 0.0625834, weight is 0.0613917 , bias is 0.46329\n",
            "After 393  step(s), loss is 0.062554, weight is 0.0612037 , bias is 0.461887\n",
            "After 394  step(s), loss is 0.0625361, weight is 0.061138 , bias is 0.46078\n",
            "After 395  step(s), loss is 0.0625251, weight is 0.0611645 , bias is 0.4599\n",
            "After 396  step(s), loss is 0.0625181, weight is 0.0612604 , bias is 0.459193\n",
            "After 397  step(s), loss is 0.0625135, weight is 0.0614081 , bias is 0.458621\n",
            "After 398  step(s), loss is 0.0625102, weight is 0.0615944 , bias is 0.458151\n",
            "Adding run metadata fro  399\n",
            "After 399  step(s), loss is 0.0625079, weight is 0.061809 , bias is 0.45776\n",
            "At 400  step(s), loss is 0.0795526, weight is 0.0622847 , bias is 0.467378\n",
            "After 401  step(s), loss is 0.0626328, weight is 0.061723 , bias is 0.465086\n",
            "After 402  step(s), loss is 0.0625835, weight is 0.0613739 , bias is 0.463297\n",
            "After 403  step(s), loss is 0.062554, weight is 0.0611862 , bias is 0.461895\n",
            "After 404  step(s), loss is 0.0625362, weight is 0.0611207 , bias is 0.460788\n",
            "After 405  step(s), loss is 0.0625252, weight is 0.0611475 , bias is 0.459907\n",
            "After 406  step(s), loss is 0.0625182, weight is 0.0612437 , bias is 0.459201\n",
            "After 407  step(s), loss is 0.0625135, weight is 0.0613917 , bias is 0.458628\n",
            "After 408  step(s), loss is 0.0625103, weight is 0.0615782 , bias is 0.458158\n",
            "After 409  step(s), loss is 0.0625079, weight is 0.0617931 , bias is 0.457766\n",
            "At 410  step(s), loss is 0.079552, weight is 0.062269 , bias is 0.467385\n",
            "After 411  step(s), loss is 0.0626329, weight is 0.0617075 , bias is 0.465093\n",
            "After 412  step(s), loss is 0.0625836, weight is 0.0613587 , bias is 0.463304\n",
            "After 413  step(s), loss is 0.0625541, weight is 0.0611712 , bias is 0.461901\n",
            "After 414  step(s), loss is 0.0625363, weight is 0.061106 , bias is 0.460794\n",
            "After 415  step(s), loss is 0.0625253, weight is 0.061133 , bias is 0.459914\n",
            "After 416  step(s), loss is 0.0625182, weight is 0.0612294 , bias is 0.459207\n",
            "After 417  step(s), loss is 0.0625136, weight is 0.0613776 , bias is 0.458634\n",
            "After 418  step(s), loss is 0.0625104, weight is 0.0615644 , bias is 0.458164\n",
            "After 419  step(s), loss is 0.062508, weight is 0.0617795 , bias is 0.457772\n",
            "At 420  step(s), loss is 0.0795515, weight is 0.0622556 , bias is 0.46739\n",
            "After 421  step(s), loss is 0.062633, weight is 0.0616943 , bias is 0.465098\n",
            "After 422  step(s), loss is 0.0625836, weight is 0.0613456 , bias is 0.46331\n",
            "After 423  step(s), loss is 0.0625542, weight is 0.0611584 , bias is 0.461907\n",
            "After 424  step(s), loss is 0.0625363, weight is 0.0610934 , bias is 0.4608\n",
            "After 425  step(s), loss is 0.0625253, weight is 0.0611206 , bias is 0.459919\n",
            "After 426  step(s), loss is 0.0625183, weight is 0.0612172 , bias is 0.459212\n",
            "After 427  step(s), loss is 0.0625136, weight is 0.0613656 , bias is 0.458639\n",
            "After 428  step(s), loss is 0.0625104, weight is 0.0615526 , bias is 0.458169\n",
            "After 429  step(s), loss is 0.062508, weight is 0.0617678 , bias is 0.457777\n",
            "At 430  step(s), loss is 0.0795511, weight is 0.0622441 , bias is 0.467395\n",
            "After 431  step(s), loss is 0.062633, weight is 0.061683 , bias is 0.465103\n",
            "After 432  step(s), loss is 0.0625837, weight is 0.0613345 , bias is 0.463315\n",
            "After 433  step(s), loss is 0.0625542, weight is 0.0611475 , bias is 0.461912\n",
            "After 434  step(s), loss is 0.0625364, weight is 0.0610826 , bias is 0.460804\n",
            "After 435  step(s), loss is 0.0625253, weight is 0.06111 , bias is 0.459924\n",
            "After 436  step(s), loss is 0.0625183, weight is 0.0612068 , bias is 0.459217\n",
            "After 437  step(s), loss is 0.0625137, weight is 0.0613554 , bias is 0.458644\n",
            "After 438  step(s), loss is 0.0625104, weight is 0.0615425 , bias is 0.458173\n",
            "After 439  step(s), loss is 0.062508, weight is 0.0617579 , bias is 0.457782\n",
            "At 440  step(s), loss is 0.0795507, weight is 0.0622343 , bias is 0.4674\n",
            "After 441  step(s), loss is 0.0626331, weight is 0.0616733 , bias is 0.465107\n",
            "After 442  step(s), loss is 0.0625837, weight is 0.061325 , bias is 0.463319\n",
            "After 443  step(s), loss is 0.0625542, weight is 0.0611381 , bias is 0.461916\n",
            "After 444  step(s), loss is 0.0625364, weight is 0.0610734 , bias is 0.460808\n",
            "After 445  step(s), loss is 0.0625254, weight is 0.0611009 , bias is 0.459928\n",
            "After 446  step(s), loss is 0.0625184, weight is 0.0611978 , bias is 0.459221\n",
            "After 447  step(s), loss is 0.0625137, weight is 0.0613466 , bias is 0.458648\n",
            "After 448  step(s), loss is 0.0625105, weight is 0.0615338 , bias is 0.458177\n",
            "After 449  step(s), loss is 0.0625081, weight is 0.0617494 , bias is 0.457786\n",
            "At 450  step(s), loss is 0.0795504, weight is 0.0622259 , bias is 0.467403\n",
            "After 451  step(s), loss is 0.0626331, weight is 0.0616651 , bias is 0.465111\n",
            "After 452  step(s), loss is 0.0625838, weight is 0.0613169 , bias is 0.463322\n",
            "After 453  step(s), loss is 0.0625543, weight is 0.0611301 , bias is 0.461919\n",
            "After 454  step(s), loss is 0.0625364, weight is 0.0610655 , bias is 0.460812\n",
            "After 455  step(s), loss is 0.0625254, weight is 0.0610932 , bias is 0.459931\n",
            "After 456  step(s), loss is 0.0625184, weight is 0.0611902 , bias is 0.459224\n",
            "After 457  step(s), loss is 0.0625138, weight is 0.0613391 , bias is 0.458651\n",
            "After 458  step(s), loss is 0.0625105, weight is 0.0615264 , bias is 0.45818\n",
            "After 459  step(s), loss is 0.0625081, weight is 0.0617421 , bias is 0.457789\n",
            "At 460  step(s), loss is 0.0795501, weight is 0.0622187 , bias is 0.467407\n",
            "After 461  step(s), loss is 0.0626331, weight is 0.061658 , bias is 0.465114\n",
            "After 462  step(s), loss is 0.0625838, weight is 0.06131 , bias is 0.463325\n",
            "After 463  step(s), loss is 0.0625543, weight is 0.0611233 , bias is 0.461922\n",
            "After 464  step(s), loss is 0.0625365, weight is 0.0610588 , bias is 0.460815\n",
            "After 465  step(s), loss is 0.0625254, weight is 0.0610866 , bias is 0.459934\n",
            "After 466  step(s), loss is 0.0625184, weight is 0.0611837 , bias is 0.459227\n",
            "After 467  step(s), loss is 0.0625138, weight is 0.0613327 , bias is 0.458654\n",
            "After 468  step(s), loss is 0.0625105, weight is 0.0615201 , bias is 0.458183\n",
            "After 469  step(s), loss is 0.0625081, weight is 0.0617359 , bias is 0.457791\n",
            "At 470  step(s), loss is 0.0795499, weight is 0.0622126 , bias is 0.467409\n",
            "After 471  step(s), loss is 0.0626331, weight is 0.061652 , bias is 0.465117\n",
            "After 472  step(s), loss is 0.0625838, weight is 0.061304 , bias is 0.463328\n",
            "After 473  step(s), loss is 0.0625543, weight is 0.0611174 , bias is 0.461925\n",
            "After 474  step(s), loss is 0.0625365, weight is 0.061053 , bias is 0.460817\n",
            "After 475  step(s), loss is 0.0625255, weight is 0.0610809 , bias is 0.459936\n",
            "After 476  step(s), loss is 0.0625185, weight is 0.0611781 , bias is 0.459229\n",
            "After 477  step(s), loss is 0.0625138, weight is 0.0613272 , bias is 0.458656\n",
            "After 478  step(s), loss is 0.0625106, weight is 0.0615147 , bias is 0.458185\n",
            "After 479  step(s), loss is 0.0625082, weight is 0.0617306 , bias is 0.457794\n",
            "At 480  step(s), loss is 0.0795497, weight is 0.0622074 , bias is 0.467411\n",
            "After 481  step(s), loss is 0.0626332, weight is 0.0616468 , bias is 0.465119\n",
            "After 482  step(s), loss is 0.0625838, weight is 0.0612989 , bias is 0.46333\n",
            "After 483  step(s), loss is 0.0625544, weight is 0.0611124 , bias is 0.461927\n",
            "After 484  step(s), loss is 0.0625365, weight is 0.0610481 , bias is 0.460819\n",
            "After 485  step(s), loss is 0.0625255, weight is 0.0610761 , bias is 0.459938\n",
            "After 486  step(s), loss is 0.0625185, weight is 0.0611734 , bias is 0.459231\n",
            "After 487  step(s), loss is 0.0625138, weight is 0.0613225 , bias is 0.458658\n",
            "After 488  step(s), loss is 0.0625106, weight is 0.0615101 , bias is 0.458187\n",
            "After 489  step(s), loss is 0.0625082, weight is 0.061726 , bias is 0.457796\n",
            "At 490  step(s), loss is 0.0795495, weight is 0.0622029 , bias is 0.467413\n",
            "After 491  step(s), loss is 0.0626332, weight is 0.0616424 , bias is 0.465121\n",
            "After 492  step(s), loss is 0.0625839, weight is 0.0612946 , bias is 0.463332\n",
            "After 493  step(s), loss is 0.0625544, weight is 0.0611082 , bias is 0.461929\n",
            "After 494  step(s), loss is 0.0625365, weight is 0.0610439 , bias is 0.460821\n",
            "After 495  step(s), loss is 0.0625255, weight is 0.0610719 , bias is 0.45994\n",
            "After 496  step(s), loss is 0.0625185, weight is 0.0611693 , bias is 0.459233\n",
            "After 497  step(s), loss is 0.0625138, weight is 0.0613185 , bias is 0.45866\n",
            "After 498  step(s), loss is 0.0625106, weight is 0.0615062 , bias is 0.458189\n",
            "Adding run metadata fro  499\n",
            "After 499  step(s), loss is 0.0625082, weight is 0.0617221 , bias is 0.457797\n",
            "At 500  step(s), loss is 0.0795494, weight is 0.0621991 , bias is 0.467415\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqMAAAKdCAYAAAAX72C1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f8bc61c4d68>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Done !!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rk31X14qUMIm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Freeze Graph**"
      ]
    },
    {
      "metadata": {
        "id": "RgszozhgI7yU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7e143647-9be2-4a2b-9706-4203037ae71e"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.framework import graph_util\n",
        "\n",
        "LOG_DIR = './log'\n",
        "MODELS_DIR = LOG_DIR + '/models/'\n",
        "\n",
        "def freeze_graph(model_folder,modelsName):\n",
        "    checkpoint = tf.train.get_checkpoint_state(model_folder)\n",
        "    input_checkpoint = checkpoint.model_checkpoint_path\n",
        "    #print(checkpoint)\n",
        "    #print(input_checkpoint)\n",
        "    absolute_model_folder = \"/\".join(input_checkpoint.split('/')[:-1])\n",
        "    output_graph = absolute_model_folder + \"/\"+modelsName+\".pb\"\n",
        "    #print(absolute_model_folder)\n",
        "    #print(output_graph)\n",
        "    \n",
        "    output_node_names = \"Result/out\" #now is bad!!!!\n",
        "    \n",
        "    clear_devices = True\n",
        "    \n",
        "    saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\n",
        "    #print(saver)\n",
        "    \n",
        "    graph = tf.get_default_graph()\n",
        "    \n",
        "    input_graph_def = graph.as_graph_def()\n",
        "    \n",
        "    with tf.Session() as sess:\n",
        "        saver.restore(sess, input_checkpoint)\n",
        " \n",
        "        # We use a built-in TF helper to export variables to constant\n",
        "        output_graph_def = graph_util.convert_variables_to_constants(\n",
        "            sess, \n",
        "            input_graph_def, \n",
        "            output_node_names.split(\",\") # We split on comma for convenience\n",
        "        ) \n",
        " \n",
        "        # Finally we serialize and dump the output graph to the filesystem\n",
        "        with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
        "            f.write(output_graph_def.SerializeToString())\n",
        "        print(\"%d ops in the final graph.\" % len(output_graph_def.node))\n",
        "        #print(output_graph_def.node)\n",
        "    \n",
        "with tf.Session() as sess:\n",
        "    freeze_graph(MODELS_DIR,'test')\n",
        "    #print(MODELS_DIR)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./log/models/test_model.ckpt-499\n",
            "INFO:tensorflow:Froze 2 variables.\n",
            "INFO:tensorflow:Converted 2 variables to const ops.\n",
            "7 ops in the final graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CYeqndibUT7I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Load pb Model**"
      ]
    },
    {
      "metadata": {
        "id": "MO6IZTKQUazD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "93f39a5a-5999-48ab-9a8f-997224676d55"
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.platform import gfile\n",
        "\n",
        "LOG_DIR = './log'\n",
        "MODELS_DIR = LOG_DIR + '/models/'\n",
        "\n",
        "def load(MODELS_DIR,fileName,sess):\n",
        "  graph = tf.get_default_graph()\n",
        "  graphdef = graph.as_graph_def()\n",
        "  graphdef.ParseFromString(gfile.FastGFile(MODELS_DIR+fileName, \"rb\").read())\n",
        "  #print(MODELS_DIR+fileName)\n",
        "  _ = tf.import_graph_def(graphdef)\n",
        "  summary_write = tf.summary.FileWriter(LOG_DIR + '/graph', sess.graph)\n",
        "  summary_write.close()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  \n",
        "    load(MODELS_DIR,'test.pb',sess)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-6363780767c9>:14: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fIad57Jh9cEe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **TensorBoard**"
      ]
    },
    {
      "metadata": {
        "id": "A_n-owW89cfN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "1073e8d0-1659-441e-b555-b3d308998be2"
      },
      "cell_type": "code",
      "source": [
        "#https://www.dlology.com/blog/quick-guide-to-run-tensorboard-in-google-colab/\n",
        "\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw('tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'.format(LOG_DIR))\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-10-25 01:14:38--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.4.95.48, 52.2.175.150, 52.3.53.115, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.4.95.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]   5.11M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2018-10-25 01:14:43 (39.8 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "http://c304703a.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wmpy_s3DYNFb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Test Numpy**"
      ]
    },
    {
      "metadata": {
        "id": "9zgjhJNWhxpT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f8dfa3aa-20ce-451a-85c2-be0aedd95968"
      },
      "cell_type": "code",
      "source": [
        "'''import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "MAX_STEPS = 500\n",
        "\n",
        "NUM_EXAMPLES = 10000\n",
        "\n",
        "# create data 生成100个0-1之间的随机数   np.random.rand(100) 1*100的矩阵，其每个元素为0-1的随机数\n",
        "#x_data = np.random.rand(NUM_EXAMPLES).astype(np.float32)\n",
        "\n",
        "#y_data = x_data\n",
        "\n",
        "#x_data =np.array([np.random.uniform(1,1.2, NUM_EXAMPLES),np.random.uniform(1,1.2, NUM_EXAMPLES)]) #np.array([np.linspace(1, 4, NUM_EXAMPLES), np.linspace(3, 9, NUM_EXAMPLES)])\n",
        "X = np.random.rand(NUM_EXAMPLES).astype(np.float32)\n",
        "#print(X)\n",
        "x_data = np.array([X,np.random.uniform(0,1, NUM_EXAMPLES)] + X ).reshape(NUM_EXAMPLES,2)\n",
        "print(x_data)\n",
        "\n",
        "plt.figure(figsize=(10, 10), dpi=80)\n",
        "plt.ion()\n",
        "plt.title(\" Diagram.\")\n",
        "plt.xlabel(\"x_data\")\n",
        "plt.ylabel(\"y_\")\n",
        "#plt.xlim(xmax=1, xmin=0)\n",
        "#plt.ylim(ymax=1,ymin=0)\n",
        "plt.plot(x_data[0:1],x_data[0:1],'ro',color='r',linewidth=0.5)\n",
        "plt.ioff()\n",
        "plt.show()'''"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import matplotlib.pyplot as plt\\n\\nimport numpy as np\\n\\nMAX_STEPS = 500\\n\\nNUM_EXAMPLES = 10000\\n\\n# create data 生成100个0-1之间的随机数   np.random.rand(100) 1*100的矩阵，其每个元素为0-1的随机数\\n#x_data = np.random.rand(NUM_EXAMPLES).astype(np.float32)\\n\\n#y_data = x_data\\n\\n#x_data =np.array([np.random.uniform(1,1.2, NUM_EXAMPLES),np.random.uniform(1,1.2, NUM_EXAMPLES)]) #np.array([np.linspace(1, 4, NUM_EXAMPLES), np.linspace(3, 9, NUM_EXAMPLES)])\\nX = np.random.rand(NUM_EXAMPLES).astype(np.float32)\\n#print(X)\\nx_data = np.array([X,np.random.uniform(0,1, NUM_EXAMPLES)] + X ).reshape(NUM_EXAMPLES,2)\\nprint(x_data)\\n\\nplt.figure(figsize=(10, 10), dpi=80)\\nplt.ion()\\nplt.title(\" Diagram.\")\\nplt.xlabel(\"x_data\")\\nplt.ylabel(\"y_\")\\n#plt.xlim(xmax=1, xmin=0)\\n#plt.ylim(ymax=1,ymin=0)\\nplt.plot(x_data[0:1],x_data[0:1],\\'ro\\',color=\\'r\\',linewidth=0.5)\\nplt.ioff()\\nplt.show()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "toTJiz6iYAuC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Tensorboard Projector**"
      ]
    },
    {
      "metadata": {
        "id": "nvnaWQIOTBy7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "323faa8a-7a51-4ba6-eec1-77b6ee2068b6"
      },
      "cell_type": "code",
      "source": [
        "'''import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tensorflow.contrib.tensorboard.plugins import projector\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "LOG_DIR = './'\n",
        "NAME_TO_VISUALISE_VARIABLE = \"mnistembedding\"\n",
        "TO_EMBED_COUNT = 500\n",
        "\n",
        "\n",
        "path_for_mnist_sprites ='mnistdigits.png'  #os.path.join(LOG_DIR,'mnistdigits.png')\n",
        "path_for_mnist_metadata ='metadata.tsv'  #os.path.join(LOG_DIR,'metadata.tsv')\n",
        "\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n",
        "batch_xs, batch_ys = mnist.train.next_batch(TO_EMBED_COUNT)\n",
        "\n",
        "embedding_var = tf.Variable(batch_xs, name=NAME_TO_VISUALISE_VARIABLE)\n",
        "summary_writer = tf.summary.FileWriter(LOG_DIR)\n",
        "\n",
        "config = projector.ProjectorConfig()\n",
        "embedding = config.embeddings.add()\n",
        "embedding.tensor_name = embedding_var.name\n",
        "\n",
        "# Specify where you find the metadata\n",
        "embedding.metadata_path = path_for_mnist_metadata #'metadata.tsv'\n",
        "\n",
        "# Specify where you find the sprite (we will create this later)\n",
        "embedding.sprite.image_path = path_for_mnist_sprites #'mnistdigits.png'\n",
        "embedding.sprite.single_image_dim.extend([28,28])\n",
        "\n",
        "# Say that you want to visualise the embeddings\n",
        "projector.visualize_embeddings(summary_writer, config)\n",
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "saver = tf.train.Saver()\n",
        "saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"), 1)\n",
        "\n",
        "\n",
        "def create_sprite_image(images):\n",
        "    \"\"\"Returns a sprite image consisting of images passed as argument. Images should be count x width x height\"\"\"\n",
        "    if isinstance(images, list):\n",
        "        images = np.array(images)\n",
        "    img_h = images.shape[1]\n",
        "    img_w = images.shape[2]\n",
        "    n_plots = int(np.ceil(np.sqrt(images.shape[0])))\n",
        "\n",
        "\n",
        "    spriteimage = np.ones((img_h * n_plots ,img_w * n_plots ))\n",
        "\n",
        "    for i in range(n_plots):\n",
        "        for j in range(n_plots):\n",
        "            this_filter = i * n_plots + j\n",
        "            if this_filter < images.shape[0]:\n",
        "                this_img = images[this_filter]\n",
        "                spriteimage[i * img_h:(i + 1) * img_h,\n",
        "                  j * img_w:(j + 1) * img_w] = this_img\n",
        "\n",
        "    return spriteimage\n",
        "\n",
        "def vector_to_matrix_mnist(mnist_digits):\n",
        "    \"\"\"Reshapes normal mnist digit (batch,28*28) to matrix (batch,28,28)\"\"\"\n",
        "    return np.reshape(mnist_digits,(-1,28,28))\n",
        "\n",
        "def invert_grayscale(mnist_digits):\n",
        "    \"\"\" Makes black white, and white black \"\"\"\n",
        "    return 1-mnist_digits\n",
        "to_visualise = batch_xs\n",
        "to_visualise = vector_to_matrix_mnist(to_visualise)\n",
        "to_visualise = invert_grayscale(to_visualise)\n",
        "\n",
        "sprite_image = create_sprite_image(to_visualise)\n",
        "\n",
        "plt.imsave(path_for_mnist_sprites,sprite_image,cmap='gray')\n",
        "plt.imshow(sprite_image,cmap='gray')\n",
        "\n",
        "with open(path_for_mnist_metadata,'w') as f:\n",
        "    f.write(\"Index\\tLabel\\n\")\n",
        "    for index,label in enumerate(batch_ys):\n",
        "        f.write(\"%d\\t%d\\n\" % (index,label))\n",
        "print(\"Done !!!\")\n",
        "\n",
        "#https://www.dlology.com/blog/quick-guide-to-run-tensorboard-in-google-colab/\n",
        "\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "LOG_DIR = './'\n",
        "get_ipython().system_raw('tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'.format(LOG_DIR))\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"'''"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import matplotlib.pyplot as plt\\nimport tensorflow as tf\\nimport numpy as np\\nimport os\\n\\nfrom tensorflow.contrib.tensorboard.plugins import projector\\nfrom tensorflow.examples.tutorials.mnist import input_data\\n\\nLOG_DIR = \\'./\\'\\nNAME_TO_VISUALISE_VARIABLE = \"mnistembedding\"\\nTO_EMBED_COUNT = 500\\n\\n\\npath_for_mnist_sprites =\\'mnistdigits.png\\'  #os.path.join(LOG_DIR,\\'mnistdigits.png\\')\\npath_for_mnist_metadata =\\'metadata.tsv\\'  #os.path.join(LOG_DIR,\\'metadata.tsv\\')\\n\\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\\nbatch_xs, batch_ys = mnist.train.next_batch(TO_EMBED_COUNT)\\n\\nembedding_var = tf.Variable(batch_xs, name=NAME_TO_VISUALISE_VARIABLE)\\nsummary_writer = tf.summary.FileWriter(LOG_DIR)\\n\\nconfig = projector.ProjectorConfig()\\nembedding = config.embeddings.add()\\nembedding.tensor_name = embedding_var.name\\n\\n# Specify where you find the metadata\\nembedding.metadata_path = path_for_mnist_metadata #\\'metadata.tsv\\'\\n\\n# Specify where you find the sprite (we will create this later)\\nembedding.sprite.image_path = path_for_mnist_sprites #\\'mnistdigits.png\\'\\nembedding.sprite.single_image_dim.extend([28,28])\\n\\n# Say that you want to visualise the embeddings\\nprojector.visualize_embeddings(summary_writer, config)\\nsess = tf.InteractiveSession()\\nsess.run(tf.global_variables_initializer())\\nsaver = tf.train.Saver()\\nsaver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"), 1)\\n\\n\\ndef create_sprite_image(images):\\n    \"\"\"Returns a sprite image consisting of images passed as argument. Images should be count x width x height\"\"\"\\n    if isinstance(images, list):\\n        images = np.array(images)\\n    img_h = images.shape[1]\\n    img_w = images.shape[2]\\n    n_plots = int(np.ceil(np.sqrt(images.shape[0])))\\n\\n\\n    spriteimage = np.ones((img_h * n_plots ,img_w * n_plots ))\\n\\n    for i in range(n_plots):\\n        for j in range(n_plots):\\n            this_filter = i * n_plots + j\\n            if this_filter < images.shape[0]:\\n                this_img = images[this_filter]\\n                spriteimage[i * img_h:(i + 1) * img_h,\\n                  j * img_w:(j + 1) * img_w] = this_img\\n\\n    return spriteimage\\n\\ndef vector_to_matrix_mnist(mnist_digits):\\n    \"\"\"Reshapes normal mnist digit (batch,28*28) to matrix (batch,28,28)\"\"\"\\n    return np.reshape(mnist_digits,(-1,28,28))\\n\\ndef invert_grayscale(mnist_digits):\\n    \"\"\" Makes black white, and white black \"\"\"\\n    return 1-mnist_digits\\nto_visualise = batch_xs\\nto_visualise = vector_to_matrix_mnist(to_visualise)\\nto_visualise = invert_grayscale(to_visualise)\\n\\nsprite_image = create_sprite_image(to_visualise)\\n\\nplt.imsave(path_for_mnist_sprites,sprite_image,cmap=\\'gray\\')\\nplt.imshow(sprite_image,cmap=\\'gray\\')\\n\\nwith open(path_for_mnist_metadata,\\'w\\') as f:\\n    f.write(\"Index\\tLabel\\n\")\\n    for index,label in enumerate(batch_ys):\\n        f.write(\"%d\\t%d\\n\" % (index,label))\\nprint(\"Done !!!\")\\n\\n#https://www.dlology.com/blog/quick-guide-to-run-tensorboard-in-google-colab/\\n\\n!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\\n!unzip ngrok-stable-linux-amd64.zip\\n\\nLOG_DIR = \\'./\\'\\nget_ipython().system_raw(\\'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &\\'.format(LOG_DIR))\\n\\nget_ipython().system_raw(\\'./ngrok http 6006 &\\')\\n\\n\\n! curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)[\\'tunnels\\'][0][\\'public_url\\'])\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}